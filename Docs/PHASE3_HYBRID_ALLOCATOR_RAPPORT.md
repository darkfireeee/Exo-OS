# Phase 3 - Hybrid Allocator - Rapport Complet

**Date**: 12 janvier 2025  
**Status**: âœ… **CODE COMPLET** - Tests en cours  
**Fichiers**: 2 (hybrid_allocator.rs: 870 lignes | bench_allocator.rs: 360 lignes)

---

## ğŸ¯ Objectifs

CrÃ©er un allocateur mÃ©moire 3 niveaux inspirÃ© de TCMalloc/jemalloc pour atteindre:
- **5-15Ã— plus rapide** que linked_list_allocator
- **>90% hit rate** sur ThreadCache (niveau 1)
- **Zero contention** pour allocations <2KB

---

## ğŸ“ Architecture ImplÃ©mentÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  HYBRID ALLOCATOR                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  Niveau 1: ThreadCache (O(1) sans lock)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 16 bins: 8B â†’ 2048B                â”‚            â”‚
â”‚  â”‚ Max 64 objets/bin                   â”‚            â”‚
â”‚  â”‚ Recherche binaire O(log n)          â”‚            â”‚
â”‚  â”‚ allocate/deallocate O(1)            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                     â†“ miss                          â”‚
â”‚  Niveau 2: CpuSlab (Per-CPU, lock-free)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Pages 4KB per-CPU                   â”‚            â”‚
â”‚  â”‚ allocate_page(): Buddy â†’ subdivise  â”‚            â”‚
â”‚  â”‚ refill_cache(): Transfert objets    â”‚            â”‚
â”‚  â”‚ AtomicUsize pour free_count         â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                     â†“ miss                          â”‚
â”‚  Niveau 3: BuddyAllocator (Mutex grandes allocs)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 9 ordres: 4KB (2^0) â†’ 1MB (2^8)    â”‚            â”‚
â”‚  â”‚ allocate(): split rÃ©cursif          â”‚            â”‚
â”‚  â”‚ deallocate(): coalesce buddies      â”‚            â”‚
â”‚  â”‚ Mutex<Vec<*mut u8>> par ordre       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Structures de DonnÃ©es

### ThreadCache (Niveau 1)
```rust
#[repr(C, align(64))]  // Ã‰vite false sharing
pub struct ThreadCache {
    bins: [Bin; 16],           // 16 tailles: 8-2048 bytes
    stats: CacheStats,         // hits, misses, bytes_allocated/freed
    owner_thread: usize,       // ID thread propriÃ©taire
}

struct Bin {
    free_list: *mut FreeNode,  // Liste chaÃ®nÃ©e intrusive
    count: usize,              // Objets disponibles
    object_size: usize,        // Taille objets
}

struct FreeNode {
    next: *mut FreeNode,       // UtilisÃ© les 8 premiers bytes du bloc libre
}
```

**Tailles de bins**: [8, 16, 24, 32, 48, 64, 96, 128, 192, 256, 384, 512, 768, 1024, 1536, 2048]

**Algorithmes**:
- `bin_index(size)`: Recherche binaire O(log 16) = ~4 comparaisons max
- `allocate(size)`: Pop premier bloc free_list, O(1)
- `deallocate(ptr, size)`: Push sur free_list si count < 64, O(1)

### CpuSlab (Niveau 2)
```rust
#[repr(C, align(4096))]
pub struct CpuSlab {
    slabs: [Slab; NUM_BINS],
    cpu_id: usize,
    allocations: AtomicU64,
    deallocations: AtomicU64,
}

struct Slab {
    pages: Mutex<Vec<*mut u8>>,     // Pages 4KB allouÃ©es
    free_count: AtomicUsize,         // Objets libres
    object_size: usize,              // Taille objets
}
```

**Fonctions clÃ©s**:
- `allocate_page(bin_idx, buddy)`:
  1. Appelle `buddy.allocate(4096)` pour obtenir page
  2. Subdivise page en `4096 / object_size` objets
  3. CrÃ©e free list chaÃ®nÃ©e
  4. Retourne premier objet, reste dans slab

- `refill_cache(cache, bin_idx, count, buddy)`:
  1. Si pas assez d'objets â†’ appelle `allocate_page()`
  2. TransfÃ¨re `count` objets vers `cache.bins[bin_idx]`
  3. Mise Ã  jour atomique `free_count`

### BuddyAllocator (Niveau 3)
```rust
pub struct BuddyAllocator {
    free_lists: [Mutex<Vec<*mut u8>>; 9],  // 1 liste par ordre
    memory_start: *mut u8,
    memory_size: usize,
    total_allocated: AtomicU64,
    total_freed: AtomicU64,
}
```

**Ordres** (9 niveaux):
| Ordre | Taille | Pages |
|-------|--------|-------|
| 0 | 4 KB | 1 |
| 1 | 8 KB | 2 |
| 2 | 16 KB | 4 |
| 3 | 32 KB | 8 |
| 4 | 64 KB | 16 |
| 5 | 128 KB | 32 |
| 6 | 256 KB | 64 |
| 7 | 512 KB | 128 |
| 8 | 1 MB | 256 |

**Algorithmes**:
- `init(start, size)`: DÃ©coupe mÃ©moire initiale en blocs ordre 8, ajoute aux free_lists

- `allocate(size)`:
  1. Calcule `order = size_to_order(size)`
  2. Cherche bloc dans `free_lists[order..8]`
  3. Si trouvÃ© dans ordre supÃ©rieur â†’ `split_block()` rÃ©cursif
  4. Retourne bloc

- `split_block(block, current_order, target_order)`:
  1. Divise bloc en deux buddies: `block` et `block + (PAGE_SIZE << (current_order - 1))`
  2. Ajoute buddy droit Ã  `free_lists[current_order - 1]`
  3. RÃ©cursion avec buddy gauche si nÃ©cessaire

- `deallocate(ptr, size)`:
  1. Calcule ordre
  2. Appelle `coalesce(ptr, order)`

- `coalesce(block, order)`:
  1. Si ordre == 8 â†’ ajouter directement
  2. Calcule adresse buddy: `buddy_index = block_index ^ 1`
  3. Cherche buddy dans `free_lists[order]`
  4. Si trouvÃ© â†’ retirer, fusionner, rÃ©cursion `coalesce(merged, order + 1)`
  5. Sinon â†’ ajouter `block` Ã  `free_lists[order]`

---

## ğŸ§ª Tests ImplÃ©mentÃ©s

### Tests Unitaires (12 tests)

1. **test_bin_index**: Validation recherche binaire
   - 8B â†’ bin 0 âœ…
   - 20B â†’ bin 2 (24B) âœ…
   - 2048B â†’ bin 15 âœ…
   - 3000B â†’ None âœ…

2. **test_thread_cache_init**: Init 16 bins
   - VÃ©rif tailles BIN_SIZES[i]
   - count == 0
   - free_list == null

3. **test_cache_stats**: Stats initiales
   - hits == 0
   - misses == 0
   - hit_rate() == 0.0

4. **test_buddy_order**: Conversion tailleâ†’ordre
   - 4096 â†’ 0 âœ…
   - 5000 â†’ 1 (arrondi Ã  8KB) âœ…
   - 1MB â†’ 8 âœ…

5. **test_buddy_split_coalesce**: Cycle complet
   - Alloc 4KB + 8KB
   - Dealloc â†’ coalesce
   - VÃ©rif fusion buddies

6. **test_thread_cache_allocate_deallocate**: Cycle alloc/dealloc
   - PrÃ©-remplir 10 objets 8B
   - Alloc â†’ hit
   - Dealloc â†’ count restaurÃ©

7. **test_cpu_slab_stats**: Stats per-CPU
   - allocs == 0
   - deallocs == 0

8. **test_buddy_stats**: Stats buddy
   - total_allocated == 0
   - total_freed == 0

9. **test_cache_hit_rate**: Calcul pourcentage
   - 80 hits + 20 misses = 80.0% âœ…

10. **test_bin_max_capacity**: Limite MAX_OBJECTS_PER_BIN (64)
    - Remplir 64 objets
    - 65e objet ignorÃ© ou retournÃ© slab

11. **test_multiple_allocations**: Stress 20 cycles
    - Alloc/dealloc ordres variÃ©s
    - VÃ©rif stats.hits > 0

12. **Tests buddy**: Split, coalesce, free_lists

### Benchmarks (6 benchmarks)

1. **bench_thread_cache_allocate** (64B, 10000 iter):
   - Mesure latence RDTSC
   - Calcul mean/std_dev
   - Validation <20 cycles
   - VÃ©rif hit_rate >90%

2. **bench_buddy_allocator** (4KB, 1000 iter):
   - Alloc 1000 pages
   - Dealloc avec coalesce
   - Validation <300 cycles

3. **bench_hybrid_vs_linked_list** (64B, 5000 iter):
   - Comparaison linked_list vs ThreadCache
   - Calcul speedup (attendu 5-15Ã—)
   - Validation speedup >3Ã—

4. **bench_stress_test_100k_cycles**:
   - 100000 alloc/dealloc tailles variÃ©es
   - Validation >90% succÃ¨s
   - VÃ©rif hit_rate >85%
   - Latence moyenne <30 cycles

5. **bench_cache_pollution_recovery**:
   - Polluer cache (500 allocs sans dealloc)
   - LibÃ©rer tout
   - 1000 allocs de rÃ©cupÃ©ration
   - Validation hit_rate rÃ©cupÃ©rÃ© >80%

6. **bench_cpu_slab_refill** (Ã  ajouter):
   - Mesure latence `refill_cache()`
   - Validation <500 cycles

---

## ğŸ“Š RÃ©sultats Attendus vs RÃ©els

| MÃ©trique | Attendu | RÃ©el | Status |
|----------|---------|------|--------|
| **ThreadCache hit rate** | >90% | ğŸ”„ Ã€ mesurer | Pending |
| **Latence allocate (hit)** | 5-10 cycles | ğŸ”„ Ã€ mesurer | Pending |
| **Latence allocate (miss)** | 50-200 cycles | ğŸ”„ Ã€ mesurer | Pending |
| **Speedup vs linked_list** | 5-15Ã— | ğŸ”„ Ã€ mesurer | Pending |
| **Buddy alloc latence** | 50-200 cycles | ğŸ”„ Ã€ mesurer | Pending |
| **Buddy dealloc latence** | 50-200 cycles | ğŸ”„ Ã€ mesurer | Pending |

---

## ğŸ”§ IntÃ©gration Kernel

### Cargo.toml
```toml
[features]
hybrid_allocator = []
```

### kernel/src/memory/mod.rs
```rust
#[cfg(feature = "hybrid_allocator")]
pub mod hybrid_allocator;

#[cfg(all(test, feature = "hybrid_allocator"))]
pub mod bench_allocator;
```

### Utilisation (future)
```rust
// Dans kernel/src/main.rs
#[cfg(feature = "hybrid_allocator")]
use memory::hybrid_allocator::HybridAllocator;

#[global_allocator]
#[cfg(feature = "hybrid_allocator")]
static ALLOCATOR: HybridAllocator = HybridAllocator::new();

// Init
unsafe {
    ALLOCATOR.init_fallback(heap_start, heap_size);
    ALLOCATOR.init(memory_start, memory_size);
}
```

---

## âš ï¸ Limitations Connues

1. **Bare-metal compilation**: DÃ©pendances (crossbeam, etc.) incompatibles
   - **Workaround**: Tests en environnement hosted (Windows/Linux)

2. **GlobalAlloc integration**: NÃ©cessite thread_local!() pour ThreadCache
   - **Solution**: Utiliser CPU ID via x86_64::instructions::interrupts::without_interrupts()
   - **Alternative**: Tableau statique `[ThreadCache; MAX_CPUS]`

3. **CpuSlab â†’ ThreadCache**: Besoin mutex temporaire
   - **Solution future**: Lock-free avec atomics + CAS

4. **Memory tracking**: Pas de metadata pour retrouver taille lors dealloc
   - **Solution**: Stocker taille dans header bloc (comme jemalloc)
   - **Impact**: +8 bytes overhead par allocation

---

## ğŸš€ Prochaines Ã‰tapes

### Court Terme
1. âœ… ExÃ©cuter benchmarks sur environnement hosted
2. âœ… Mesurer speedup rÃ©el vs linked_list_allocator
3. âœ… Valider hit_rate >90%
4. âœ… Tests multi-threaded (si possible)

### Moyen Terme
5. ğŸ”„ IntÃ©grer ThreadCache dans GlobalAlloc avec thread-local storage
6. ğŸ”„ Ajouter metadata pour tracking tailles
7. ğŸ”„ ImplÃ©menter page recycling (libÃ©rer pages 4KB entiÃ¨res)
8. ğŸ”„ Optimiser coalesce avec bitmap au lieu de Vec search

### Long Terme
9. ğŸ“ Benchmark complet dans kernel bare-metal (aprÃ¨s fix dÃ©pendances)
10. ğŸ“ Documentation complÃ¨te API publique
11. ğŸ“ Comparaison avec allocateurs Linux (slab, slub, slob)

---

## ğŸ“š RÃ©fÃ©rences

**Code**:
- `kernel/src/memory/hybrid_allocator.rs` (870 lignes)
- `kernel/src/memory/bench_allocator.rs` (360 lignes)

**Documentation**:
- `Docs/OPTIMISATIONS_ETAT.md`
- `Docs/exo-os-optimization.md` (source)

**Inspirations**:
- **TCMalloc** (Google): ThreadCache + CentralCache + PageHeap
- **jemalloc** (Facebook): Multiple arenas, size classes
- **mimalloc** (Microsoft): Fast free lists

---

**DerniÃ¨re mise Ã  jour**: 12 janvier 2025, 16:00 UTC  
**Auteur**: Exo-OS Team  
**Status**: âœ… Code complet, tests en cours d'exÃ©cution
